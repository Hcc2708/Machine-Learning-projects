{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9c23f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing Values :  area                       0\n",
      "perimeter                  0\n",
      "compactness                0\n",
      "length_of_kernel           0\n",
      "width_of_kernel            0\n",
      "asymmetry_coefficient      0\n",
      "length_of_kernel_groove    0\n",
      "class                      0\n",
      "dtype: int64\n",
      "Logistic Regression: Mean accuracy - 0.9047794117647058, Std - 0.06561135341716276\n",
      "Decision Tree: Mean accuracy - 0.88125, Std - 0.11223837803291799\n",
      "Random Forest: Mean accuracy - 0.9051470588235293, Std - 0.10275455773321249\n",
      "Best parameters for Decision Tree:  {'criterion': 'entropy', 'max_depth': 4}\n",
      "Best parameters for Random Forest:  {'max_depth': 4, 'n_estimators': 10}\n",
      "Accuracy score for Decision Tree:  0.9523809523809523\n",
      "Confusion matrix for Decision Tree: \n",
      " [[10  0  1]\n",
      " [ 0 14  0]\n",
      " [ 1  0 16]]\n",
      "Accuracy score for Random Forest:  0.8333333333333334\n",
      "Confusion matrix for Random Forest: \n",
      " [[ 9  0  2]\n",
      " [ 1 13  0]\n",
      " [ 4  0 13]]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Loading the dataset\n",
    "url = 'seeds_dataset1.txt'\n",
    "names = ['area', 'perimeter', 'compactness', 'length_of_kernel', 'width_of_kernel', 'asymmetry_coefficient', 'length_of_kernel_groove', 'class']\n",
    "seeds_df = pd.read_csv(url, names=names, header=None, delimiter='\\t')\n",
    "\n",
    "# Data preprocessing\n",
    "print(\"Total missing Values : \", seeds_df.isna().sum())\n",
    "X = seeds_df.iloc[:, :-1].values\n",
    "y = seeds_df.iloc[:, -1].values\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Building and training the classification models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = f\"{name}: Mean accuracy - {cv_results.mean()}, Std - {cv_results.std()}\"\n",
    "    print(msg)\n",
    "\n",
    "# Hyperparameter tuning for Decision Tree and Random Forest\n",
    "param_grid_dt = {'criterion': ['gini', 'entropy'], 'max_depth': [2, 4, 6, 8, 10]}\n",
    "param_grid_rf = {'n_estimators': [10, 50, 100], 'max_depth': [2, 4, 6, 8, 10]}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=10, scoring='accuracy')\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=10, scoring='accuracy')\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree: \", grid_dt.best_params_)\n",
    "print(\"Best parameters for Random Forest: \", grid_rf.best_params_)\n",
    "\n",
    "# Predicting and evaluating the models on the test set\n",
    "dt = DecisionTreeClassifier(**grid_dt.best_params_)\n",
    "rf = RandomForestClassifier(**grid_rf.best_params_)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score for Decision Tree: \", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Confusion matrix for Decision Tree: \\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "print(\"Accuracy score for Random Forest: \", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Confusion matrix for Random Forest: \\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f1fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
